%        File: hw3.tex
%     Created: Sun Apr 10 07:00 PM 2016 C
% Last Change: Sun Apr 10 07:00 PM 2016 C
%

\documentclass[a4paper]{article}

\title{Math 8584 Homework 3 }
\date{4/18/16}
\author{Trevor Steil}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem*{claim}{Claim}
\newtheorem*{problem}{Problem}
%\newtheorem*{lemma}{Lemma}
\newtheorem{definition}{Definition}[section]

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\supp}[1]{\mathop{\mathrm{supp}}\left(#1\right)}
\newcommand{\lip}[1]{\mathop{\mathrm{Lip}}\left(#1\right)}
\newcommand{\curl}{\mathrm{curl}}
\newcommand{\la}{\left \langle}
\newcommand{\ra}{\right \rangle}
\renewcommand{\vec}[1]{\mathbf{#1}}

\newenvironment{solution}{\emph{Solution.}}

\begin{document}
\maketitle
\begin{enumerate}
  \item Jost, pg 91 Formula 5.1.15
    \begin{claim}
      Let $u: \R^d \times \R \to \R$ satisfy
      \begin{equation*}
        u_t = \Delta u.
      \end{equation*}
      Then
      \[ u(y,T) = \mu \int_{\partial M(y, T; \mu)}^{} u(x,t) \frac{|x-y|}{2(T-t)} d \sigma \]
      where
      \[ M(y,T; \mu) = \left\{ (x,s) \in \R^d \times \R, s \leq T : \frac{1}{(4 \pi (T-s))^{d/2}} e^{-\frac{|x-y|^2}{4(T-s)} } \geq \mu \right\} .\]
    \end{claim}

    \begin{proof}
      Assume $v$ satisfies $v_t + \Delta v = 0$. Let $\nu$ be the outer unit normal to $M(y,T;\mu)$. Then
      \begin{align*}
        0 &= \int_{M(y,T;\mu)}^{} v (u_t - \Delta u) \\
        &= \int_{M(y,T;\mu)}^{} v u_t - \int_{M(y,T;\mu)}^{} v \Delta u \\
        &= \int_{\partial M(y,T;\mu)}^{} u v - \int_{M(y,T;\mu)}^{} u v_t \\
        &\quad - \int_{\partial M(y,T;\mu)}^{} v \frac{\partial u}{\partial \nu} + \int_{M(y,T;\mu)}^{} \nabla v \cdot \nabla u \\
        &= \int_{\partial M(y,T;\mu)}^{} u v - \int_{M(y,T;\mu)}^{} u v_t \\
        &\quad - \int_{\partial M(y,T;\mu)}^{} v \frac{\partial u}{\partial \nu} + \int_{\partial M(y,T;\mu)}^{} u \frac{\partial v}{\partial \nu} -
        \int_{M(y,T;\mu)}^{} u \Delta v \\
        &= \int_{\partial M(y,T;\mu)}^{} uv - \int_{\partial M(y,T;\mu)}^{} \left( v \frac{\partial u}{\partial \nu} - u \frac{\partial v}{\partial
        \nu} \right)
      \end{align*}

      Therefore,
      \[ \int_{\partial M(y,T;\mu)}^{} uv = \int_{\partial M(y,T;\mu)}^{} \left( v \frac{\partial u}{\partial \nu} - u \frac{\partial v}{\partial \nu}
      \right) .\]

      We define
      \[ \Lambda(x,y,t,t_0) = \frac{1}{(4 \pi |t-t_0|)^{d/2}} e^{\frac{|x-y|^2}{4(t_0 - t)} } .\]

      Let $v = \Lambda(x,y,T+\varepsilon, t) - \mu$ for some $\varepsilon>0$. Then $v_t + \Delta v = 0$, so we can use this $v$ in the above
      calculations.

      As calculated in Jost,
      \[ \Lambda_{x_i} (x,y,t,t_0) = \frac{x^i - y^i}{2(t_0 - t)} \Lambda(x,y,t,t_0) .\]
      Because $M(y,T;\mu)$ is defined as a level set of $\Lambda$, $\nabla \Lambda$ and $\nu_x$ are parallel. Therefore, we have
      \begin{align*}
        \frac{\partial \Lambda}{\partial \nu_x} &= - \frac{|x-y|}{2(T-t)} \Lambda \\
        &= - \frac{|x-y|}{2(T-t)}\mu \quad \parbox{5cm}{because $\Lambda=\mu$ on $\partial M(y,T;\mu)$}
      \end{align*}<++>
    \end{proof}

  \item Jost 5.1
    \begin{claim}
      Let $\Omega \subset \R^d$ be bounded, $\Omega_T = \Omega \times (0,T)$. Let
      \[ L = \sum_{i,j=1}^d a^{ij}(x,t) \frac{\partial^2}{\partial x^i \partial x^j} + \sum_{i=1}^d b^i(x,t) \frac{\partial}{\partial x^i} .\]
      be elliptic for all $(x,t) \in \Omega_T$, and suppose
      \[ u_t \leq Lu, \]
      where $u \in C^0(\overline{\Omega_T})$ is twice continuously differentiable with respect to $x \in \Omega$ and once with respect to $t \in
      (0,T)$. Then
      \[ \sup_{\Omega_T} u = \sup_{\partial^\ast \Omega_T} u. \]
    \end{claim}

    \begin{proof}
      Without loss of generality, we may assume $a^{ij} = a^{ji}$. Because $u$ is twice continuously differentiable in space, $u_{x_i x_j} = u_{x_j
      x_i}$. Therefore,
      \begin{align*}
        a^{ij} u_{x_i x_j} + a^{ji} u_{x_j x_i} &= (a^{ij} + a^{ji}) u_{x_i x_j} \\
        &= \frac{1}{2} (a^{ij} + a^{ji}) u_{x_i x_j} + \frac{1}{2} (a^{ij} + a^{ji}) u_{x_j x_i}
      \end{align*}
      So we can replace $a^{ij}$ and $a^{ji}$ with $\frac{1}{2} (a^{ij} + a^{ji})$.

      Assume $T < \infty$ and $u_t - Lu < 0$ in $\Omega_T$.
      Fix $0<\varepsilon<T$. Suppose we have $(x_0,t_0) \in \overline{\Omega}_{T-\varepsilon}$ such that
      \[ \max_{\overline{\Omega}_{T-\varepsilon}} u = u(x_0,t_0) .\]

      If $(x_0, t_0) \in \Omega_{T-\varepsilon}$, then because we have a maximum at $(x_0, t_0)$, $u_{x_i}(x_0,t_0) = 0$ for $i = 1, \dots, d$, $u_t(x_0,t_0) = 0$, and $\Delta u(x_0,t_0) \leq 0$.

      By ellipticity, we know the matrix given by $(A)_{ij} = a^{ij}$ is symmetric positive-definite. Therefore, there is an orthogonal matrix $O$
      given by $(O)_{ij} = o_{ij}$ and
      a diagonal matrix
      \[ \Lambda = \mathop{diag} (\lambda_1, \dots, \lambda_d) \]
      with $\lambda_k > 0$ for $k = 1, \dots, d$ such that
      \[ \Lambda = O A O^T .\]

      Let $y = x_0 + O(x - x_0)$. Then $x-x_0 = O^T(y-x_0)$. By use of the chain rule, we get
      \begin{align*}
        u_{x_i} &= \sum_{k=1}^d \frac{\partial y_k}{\partial x_i} u_{y_k} \\
        &= \sum_{k=1}^d o_{ki} u_{y_k}
     \end{align*}
     and
     \begin{align*}
       u_{x_i x_j} &= \sum_{k,l=1}^d \frac{\partial y_k}{\partial x_i} \frac{\partial y_l}{\partial x_j} u_{y_k y_l} \\
       &= \sum_{k,l=1}^d o_{ki} o_{lj} u_{y_k y_l}
     \end{align*}

     By performing the matrix multiplication, we find that
     \begin{align*}
       (\Lambda)_{kl} &= (OAO^T)_{kl} \\
       &= \sum_{i,j=1}^d o_{ki} o_{lj} a^{ij}
     \end{align*}

     Now we have
     \begin{align*}
       Lu(x_0,t_0) &= \sum_{i,j=1}^d a^{ij} u_{x_i x_j} + \sum_{i=1}^d b^i u_{x_i} \\
       &= \sum_{i,j=1}^d a^{ij} u_{x_i x_j} \quad \text{because $u_{x_i}=0$ } \\
       &= \sum_{i,j=1}^d \sum_{k,l=1}^d o_{ki} o_{lj} a^{ij} u_{y_k y_l} \\
       &= \sum_{k,l=1}^d (\Lambda)_{kl} u_{y_k y_l} \\
       &= \sum_{k=1}^d \lambda_k u_{y_k y_k} \\
     \end{align*}
    Let $\lambda = \min_{k} \lambda_k$.
    Because $u(x_0,t_0)$ is a maximum,
    \begin{align*}
      Lu(x_0,t_0) &\leq \lambda \Delta u \\
      &\leq 0
    \end{align*}

    Because we assumed $u_t - Lu < 0$, we must have $u_t(x_0, t_0) < 0$. But $u_t(x_0,t_0) = 0$ at an interior minimum. Therefore $x \in
    \partial \Omega_{T-\varepsilon}$.

    If $(x_0, t_0) \in \Omega \times \{T-\varepsilon\}$, then as above, we would get $Lu(x_0,t_0) \leq 0$, so $u_t(x_0, t_0) < 0$, reaching the same
    contradiction as before.
    Therefore, we must have $(x_0,t_0) \in \partial^\ast \Omega_{T-\varepsilon}$.

    Because $u$ is continuous, by taking $\varepsilon \to 0$, we get $(x_0, t_0) \in \partial^\ast \Omega_T$, as desired.

    For the general case, we assume
    \[ u_t - Lu \leq 0 .\]
    Define $v = u - \varepsilon t$ for some $\varepsilon >0$. We have
    \begin{align*}
      v_t &= u_t - \varepsilon \\
      \leq Lu - \varepsilon \\
      &= Lv - \varepsilon \\
      < Lv
    \end{align*}
    Therefore, we know $v_t - Lv < 0$. We can then apply the work above to get
    \begin{align*}
      \max_{ \overline{\Omega}_T } u &= \max_{ \overline{\Omega}_T } (v + \varepsilon t) \\
      &\leq \max_{ \overline{\Omega_T} } v + \varepsilon T \\
      &= \max_{\partial^\ast \Omega_T} v + \varepsilon T \\
      &\leq \max_{\partial^\ast \Omega_T} u + \varepsilon T
    \end{align*}

    By letting $\varepsilon \to 0$, we get
    \[ \max_{\overline{\Omega}_T } u = \max_{\partial^\ast \Omega_T} u .\]
    \textbf{NEED TO CONSIDER $T=\infty$}

  \end{proof}

  \item Jost 5.4
    \begin{claim}
      Let $\Sigma$ be the grid consisting of the points $(x,t)$ with $x = nh, t = mk, n,m \in \Z, m \geq 0$, and let $v$ be the solution of the
      discrete heat equation
      \begin{equation} \label{eq:discrete_heat}
        \frac{v(x,t+k) - v(x,t)}{k} - \frac{v(x+h,t) - 2v(x,t) + v(x-h,t)}{h^2} = 0
    \end{equation}
      with $v(x,0) = f(x) \in C^0(\R)$.
      Then for $\frac{k}{h^2} = \frac{1}{2}$,
      \[ v(nh, mk) = 2^{-m} \sum_{j=0}^m \binom{m}{j} f \left( (n - m + 2j)h \right) .\]
      Also,
      \[ \sup_{\Sigma} |v| \leq \sup_\R |f|. \]
    \end{claim}

    \begin{proof}
      We will prove this claim by induction.
      First, by plugging in $k=\frac{h^2}{2}, x = nh$, and $t = mk$ in \eqref{eq:discrete_heat}, we get
      \begin{equation} \label{eq:heat_rec}
        0 = \frac{2 v(nh, (m+1)k) - 2v(nh,mk)}{h^2} - \frac{v((n+1)h,mk) - 2v(nh,mk) + v(( n-1)h,mk) }{h^2} .
      \end{equation}
      Solving for $v(nh,(m+1)k)$, we find
      \[ v(nh,(m+1)k) = \frac{1}{2} v( (n+1)h, mk) + \frac{1}{2} v( (n-1)h, mk) .\]

      We will perform induction on $m$ only. First, let $m=0$. Then for any $n \in \Z$,
      \begin{align*}
        v(nh,0) &= f(nh) \\
        &= 2^{0} \sum_{j=0}^0 \binom{0}{0} f( (n - 0 + 0)h)
      \end{align*}
      by definition, proving our base case.

      Now we assume
      \[ v(nh, mk) = 2^{-m} \sum_{j=0}^m \binom{m}{j} f \left( (n - m + 2j)h \right) .\]
      for all $n \in \Z$.

      Take any $n \in \Z$. Then by \eqref{eq:heat_rec},
      \begin{align*}
        v(nh, (m+1)k) &= \frac{1}{2} v( (n+1)h, mk) + \frac{1}{2} v( (n-1)h, mk) \\
        &= 2^{-(m+1)} \sum_{j=0}^m \binom{m}{j} f( (n+1-m+2j)h) \\
        &\quad + 2^{-(m+1)} \sum_{j=0}^m \binom{m}{j} f( (n-1-m+2j)h) \\
        &= 2^{-(m+1)} \sum_{j=1}^{m+1} \binom{m}{j-1} f( (n-(m+1)+2j)h) \\
        &\quad + 2^{-(m+1)} \sum_{j=0}^m \binom{m}{j} f( (n-(m+1)+2j)h) \\
        &= 2^{-(m+1)} \left( \binom{m}{m} f( (n + (m+1) )h) + \binom{m}{0} f( (n - (m+1))h) \right) \\
        &\quad + \sum_{j=1}^m \left( \binom{m}{j-1} \binom{m}{j} \right) f( (n-(m+1)+2j)h) \\
        &= 2^{-(m+1)} \sum_{j=0}^{m+1} \binom{m+1}{j} f( (n-(m+1)+2j)h)
      \end{align*}

      Therefore, we have
      \[ v(nh, mk) = 2^{-m} \sum_{j=0}^m \binom{m}{j} f \left( (n - m + 2j)h \right) .\]
      for all $m,n \in \Z$ with $m>0$.

      Also, we have for any $m\geq 0$
      \begin{align*}
        \sup_{n \in \Z} |v(nh,mk)| &\leq \sup_\R |f| 2^{-m} \sum_{j=0}^m \binom{m}{j} \\
        &= \sup_\R |f| 2^{-m} 2^m \\
        &= \sup_\R |f|
      \end{align*}

      Then taking the supremum over all $m \geq 0$, we get
      \[ \sup_{\Sigma} |v| \leq \sup_{\R} |f| .\]

    \end{proof}

  \item Evans pg 87 \#12
    \begin{claim}
      Suppose $u$ is smooth and solves $u_t - \Delta u = 0$ in $\R^n \times (0,\infty)$. Then
      \begin{enumerate}
        \item $u_\lambda(x,t) = u(\lambda x, \lambda^2 t)$ also solves the heat equation for each $\lambda \in \R$.

        \item $v(x,t) = x \cdot Du(x,t) + 2t u_t(x,t)$ solves the heat equation as well.
      \end{enumerate}

    \end{claim}

    \begin{proof}
      \begin{enumerate}
        \item
          A simple calculation shows
          \begin{align*}
            \partial_t u_\lambda + \Delta u_\lambda &= \lambda^2 u_t + \lambda^2 \Delta u \\
            &= \lambda^2 (u_t + \Delta u) \\
            &= 0
          \end{align*}

        \item
          By part (a), we know $u_\lambda(x,t) = u(\lambda x, \lambda^2 t)$ satisfies the heat equation.
          Write
          \[ u_\lambda(x, t) = u( \lambda x_1, \dots, \lambda x_n, \lambda^2 t) .\]
          Taking the derivative with respect to $\lambda$ gives
          \begin{align*}
            \partial_\lambda u_\lambda &= x_1 \partial_{x_1} u + \dots + \partial_{x_n} u + 2 \lambda t \partial_t u \\
            &= x \cdot Du + 2 \lambda t u_t
          \end{align*}
          By choosing $\lambda = 1$, we get $v$.
          By assumption, $u$ is smooth, so our partial derivatives commute. Therefore,
          \begin{align*}
            v_t - \Delta v &= \partial_t ( \partial_\lambda u_\lambda |_{\lambda=1} ) - \Delta ( \partial_\lambda u_\lambda |_{\lambda=1} ) \\
            &= \partial_\lambda (\partial_t u_\lambda ) |_{\lambda=1} + \partial_\lambda (\Delta u_\lambda) |_{\lambda=1} \\
            &= \partial_\lambda (\partial_t u_\lambda + \Delta u_\lambda ) |_{\lambda=1} \\
            &= 0
          \end{align*}
          because $u_\lambda$ solves the heat equation. Thus, $v$ solves the heat equation as well.
      \end{enumerate}
    \end{proof}

  \item Evans pg 87 \#13
    \begin{problem}
      Assume $n = 1$ and $u(x,t) = v\left( \frac{x}{\sqrt{t}} \right)$.
      \begin{enumerate}
        \item Show
          \[ u_t = u_{xx} \]
          if and only if
          \begin{equation} \label{eq:ODE}
            v'' + \frac{z}{2} v' = 0
          \end{equation}

          Also, show that the general solution of \eqref{eq:ODE} is
          \[ v(z) = c \int_{0}^{z} e^{-s^2/4} ds + d .\]

        \item
          Differentiate $u(x,t) = v\left( \frac{x}{\sqrt{t}} \right)$ with respect to $x$ and select the constant $c$ properly, to obtain the
          fundamental solution $\Phi$ for $n = 1$. Explain why this procedure produces the fundamental solution.

      \end{enumerate}

    \end{problem}

    \begin{solution}
      \begin{enumerate}
        \item
          Taking derivatives, we find
          \[ u_t = -\frac{x}{2 t^{3/2}} v' \]
          and
          \[ u_{xx} = \frac{1}{t} v'' .\]

          Therefore,
          \begin{align*}
            u_t = u_{xx} &\Leftrightarrow -\frac{x}{2 t^{3/2}} v' = \frac{1}{t} v'' \\
            &\Leftrightarrow -\frac{x}{2 t^{1/2}} v' = v'' \quad \text{because we assume $t>0$} \\
            &\Leftrightarrow v'' + \frac{z}{2} v' = 0
          \end{align*}

          We can solve this differential equation by introducing an integrating factor. We find
          \begin{align*}
            0 &= v'' + \frac{z}{2} v' \\
            &= \left( e^{z^2/4} v' \right)'
          \end{align*}

          Therefore,
          \[ v' = c e^{-z^2/4} .\]
          This gives us the general solution as
          \[ v = c \int_{0}^{z} e^{-s^2/4} ds + d .\]

        \item
          We have that
          \begin{align*}
            u(x,0) &= \lim_{t \to 0} v \left( \frac{x}{\sqrt{t}} \right) \\
            &= \lim_{z \to \pm \infty} c \int_{0}^{z} e^{-s^2/4} ds + d \\
          \end{align*}
          where we take $z \to \infty$ if $x>0$ and take $z \to -\infty$ if $x<0$. These integrals are Gaussians, so we have
          \begin{align*}
            u(x,0) &= \begin{cases}
              c \sqrt{\pi} + d &\text{if } x>0 \\
              -c \sqrt{\pi} + d &\text{if } x<0
          \end{cases} \\
          &= 2 c \sqrt{\pi} \mathcal{H}(x) + d - \sqrt{\pi}
        \end{align*}
        where $\mathcal{H}$ denotes the Heaviside function.

        For the fundamental solution, we want to have initial data given by $\delta$. We see that
        \[ u_x(x,0) = 2c \sqrt{\pi} \delta .\]
        Assuming smoothness, $u_x$ will satisfy the heat equation as well. Therefore with $c = \frac{1}{\sqrt{4\pi}}$, we get $u_x(x,t) = v_x \left(
        \frac{x}{\sqrt{t}} \right)$ satisfies
        \begin{equation}
          \begin{cases}
            w_t = w_{xx} &\quad \text{for $x,t \in \R, t>0$} \\
            w(x,0) = \delta
          \end{cases}
        \end{equation}

        We have
          \begin{align*}
            v \left( \frac{x}{\sqrt{t}} \right) &= \frac{1}{\sqrt{4 \pi}} \int_{0}^{\frac{x}{\sqrt{t}}} e^{-s^2/4} ds + d \\
            &= \frac{1}{\sqrt{4\pi}} \int_{0}^{x} e^{-w^2/(4t)} \frac{1}{\sqrt{t}} dw + d \quad \parbox{4cm}{by letting $s = w/\sqrt{t}$} \\
          \end{align*}

          Differentiating with respect to $x$, we get
          \[ v_x \left( \frac{x}{\sqrt{t}} \right) = \frac{1}{\sqrt{4 \pi}} e^{-x^2/(4t)} \frac{1}{\sqrt{t}} .\]

          This is the fundamental solution we wanted.
      \end{enumerate}
    \end{solution}
\end{enumerate}
\end{document}


